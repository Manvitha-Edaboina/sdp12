# -*- coding: utf-8 -*-
"""sdp3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12Q6Yrm_te-4W8cQrPgcEb6fFyJSQt4eq
"""

# Step 1: Data Preprocessing
import pandas as pd

# Load the dataset
data = pd.read_csv('Diabetes.csv')
data.head()

# Check for missing values
print(data.isnull().sum())

# Handle missing values (assuming forward fill for simplicity)
data.fillna(method='ffill', inplace=True)

# Handle missing values (assuming forward fill for simplicity)
data.fillna(method='ffill', inplace=True)

# Drop any remaining NaN values if present
data.dropna(inplace=True)

# Encode categorical variables
data = pd.get_dummies(data, columns=['Sex', 'Education'])

# Scale numerical features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
data[['BMI', 'MentHlth', 'PhysHlth']] = scaler.fit_transform(data[['BMI', 'MentHlth', 'PhysHlth']])

# Step 2: Exploratory Data Analysis (EDA)
# Conduct exploratory data analysis to gain insights into the dataset
print(data.describe())

# Step 3: Model Selection
from sklearn.ensemble import GradientBoostingClassifier

# Step 4: Baseline Model Training
X = data.drop(columns=['Diabetes_012'])
y = data['Diabetes_012']
model_baseline = GradientBoostingClassifier()
model_baseline.fit(X, y)

import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Define the dimensions of the input noise vector
latent_dim = 100

# Define the generator model
def build_generator(latent_dim):
    input_noise = Input(shape=(latent_dim,))
    x = Dense(128, activation='relu')(input_noise)
    x = Dense(256, activation='relu')(x)
    x = Dense(512, activation='relu')(x)
    output = Dense(data.shape[1], activation='sigmoid')(x)  # Output layer matches the dimension of your dataset
    generator = Model(inputs=input_noise, outputs=output)
    return generator

# Define the discriminator model
def build_discriminator(input_shape):
    input_data = Input(shape=input_shape)
    x = Dense(512, activation='relu')(input_data)
    x = Dense(256, activation='relu')(x)
    x = Dense(128, activation='relu')(x)
    output = Dense(1, activation='sigmoid')(x)
    discriminator = Model(inputs=input_data, outputs=output)
    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])
    return discriminator

# Compile the discriminator
discriminator = build_discriminator(input_shape=(data.shape[1],))
discriminator.trainable = False

# Build the GAN model
generator = build_generator(latent_dim)
gan_input = Input(shape=(latent_dim,))
synthetic_data = generator(gan_input)
gan_output = discriminator(synthetic_data)
gan = Model(gan_input, gan_output)
gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))

# Training the GAN
def train_gan(data, generator, discriminator, gan, latent_dim, epochs=10000, batch_size=128):
    for epoch in range(epochs):
        # Sample random noise for generator input
        noise = np.random.normal(0, 1, (batch_size, latent_dim))

        # Generate synthetic data
        generated_data = generator.predict(noise)

        # Select a random batch of real data
        idx = np.random.randint(0, data.shape[0], batch_size)
        real_data = data[idx]

        # Train the discriminator
        d_loss_real = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))
        d_loss_fake = discriminator.train_on_batch(generated_data, np.zeros((batch_size, 1)))
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        # Train the generator (via the GAN model)
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        valid_labels = np.ones((batch_size, 1))
        g_loss = gan.train_on_batch(noise, valid_labels)

        # Print progress
        if epoch % 100 == 0:
            print(f"Epoch {epoch}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}")

# Train the GAN
train_gan(data.values.astype('float32'), generator, discriminator, gan, latent_dim)

# Define X_train and y_train for the baseline model
X_train, y_train = data.drop(columns=['Diabetes_012']), data['Diabetes_012']

# Step 6: Model Training with Synthetic Data
# Generate synthetic data using the trained generator model

# Define the number of synthetic samples to generate
num_synthetic_samples = len(data)  # Generate as many synthetic samples as the original data

# Generate random noise for the generator input
noise = np.random.normal(0, 1, (num_synthetic_samples, latent_dim))

# Generate synthetic data
synthetic_data = generator.predict(noise)

# Combine original and synthetic data
augmented_data = np.concatenate([data.values, synthetic_data], axis=0)

# Create labels for the augmented dataset
augmented_labels = np.concatenate([np.ones(len(data)), np.zeros(len(synthetic_data))])

# Shuffle the augmented dataset
shuffled_indices = np.random.permutation(len(augmented_data))
augmented_data = augmented_data[shuffled_indices]
augmented_labels = augmented_labels[shuffled_indices]

# Split the augmented dataset into features and labels
X_augmented = augmented_data
y_augmented = augmented_labels

# Train your machine learning model using the augmented dataset
# Example:
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Split the augmented dataset into train and test sets
X_train_augmented, X_test_augmented, y_train_augmented, y_test_augmented = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42)

# Define and train your machine learning model (e.g., RandomForestClassifier)
model_augmented = RandomForestClassifier()
model_augmented.fit(X_train_augmented, y_train_augmented)

# Evaluate the model on the test set
accuracy_augmented = model_augmented.score(X_test_augmented, y_test_augmented)
print("Accuracy on augmented data:", accuracy_augmented)

# Step 6: Model Training with Synthetic Data

# Assuming you have trained the GAN and generated synthetic_data
# Combine original and synthetic data
augmented_data = np.concatenate([data.values, synthetic_data], axis=0)

# Create labels for the augmented dataset
augmented_labels = np.concatenate([np.ones(len(data)), np.zeros(len(synthetic_data))])

# Shuffle the augmented dataset
shuffled_indices = np.random.permutation(len(augmented_data))
augmented_data = augmented_data[shuffled_indices]
augmented_labels = augmented_labels[shuffled_indices]

# Split the augmented dataset into features and labels
X_augmented = augmented_data
y_augmented = augmented_labels

# Train your machine learning model using the augmented dataset
# Example:
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Split the augmented dataset into train and test sets
X_train_augmented, X_test_augmented, y_train_augmented, y_test_augmented = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42)

# Define and train your machine learning model (e.g., RandomForestClassifier)
model_augmented = RandomForestClassifier()
model_augmented.fit(X_train_augmented, y_train_augmented)

# Step 7: Model Evaluation
# Evaluate the performance of the trained models using appropriate evaluation metrics
# Compare the performance of models trained with and without synthetic data

# Assuming you have defined X_test and y_test using the original data
# Evaluate the baseline model on the original test set
X_test, y_test = data.drop(columns=['Diabetes_012']), data['Diabetes_012']
accuracy_baseline = model_baseline.score(X_test, y_test)
print("Baseline Model Accuracy:", accuracy_baseline)

# Evaluate the model trained with augmented data on the augmented test set
accuracy_augmented = model_augmented.score(X_test_augmented, y_test_augmented)
print("Model Trained with Augmented Data Accuracy:", accuracy_augmented)

# Compare the performance of the baseline and augmented models
if accuracy_augmented > accuracy_baseline:
    print("Model trained with augmented data performs better.")
else:
    print("Baseline model performs better.")

# Step 8: Hyperparameter Tuning
# Perform hyperparameter tuning to optimize the performance of the models
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Define the hyperparameters grid (reduced for faster execution)
param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [None, 10],
}

# Initialize GridSearchCV for baseline model
grid_search_baseline = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=3)
grid_search_baseline.fit(X_train, y_train)

# Initialize GridSearchCV for model trained on augmented data
grid_search_augmented = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=3)
grid_search_augmented.fit(X_train_augmented, y_train_augmented)

# Get the best hyperparameters and models
best_params_baseline = grid_search_baseline.best_params_
best_model_baseline = grid_search_baseline.best_estimator_

best_params_augmented = grid_search_augmented.best_params_
best_model_augmented = grid_search_augmented.best_estimator_

# Evaluate the best models on the test set
accuracy_baseline = best_model_baseline.score(X_test, y_test)
accuracy_augmented = best_model_augmented.score(X_test_augmented, y_test_augmented)

print("Best Model Accuracy (Baseline):", accuracy_baseline)
print("Best Model Hyperparameters (Baseline):", best_params_baseline)
print("Best Model Accuracy (Augmented Data):", accuracy_augmented)
print("Best Model Hyperparameters (Augmented Data):", best_params_augmented)

from sklearn.model_selection import cross_val_score

# Step 9: Validation and Interpretation
# Validate the trained models using cross-validation or a holdout validation set
# Interpret the results and assess the clinical relevance of the model predictions

# Validate the baseline model using cross-validation
baseline_scores = cross_val_score(best_model_baseline, X_train, y_train, cv=5)
print("Baseline Model Cross-Validation Scores:", baseline_scores)
print("Baseline Model Mean Cross-Validation Score:", baseline_scores.mean())

# Validate the model trained on augmented data using cross-validation
augmented_scores = cross_val_score(best_model_augmented, X_train_augmented, y_train_augmented, cv=5)
print("Augmented Data Model Cross-Validation Scores:", augmented_scores)
print("Augmented Data Model Mean Cross-Validation Score:", augmented_scores.mean())

from joblib import dump

# Assuming model_augmented is your trained model
dump(model_augmented, 'saved_model.pb')

from joblib import load
import numpy as np
from flask import jsonify

# Load the trained model
model = load('model.joblib')

def predict(request):
    # Parse input data from the request
    data = request.get_json()
    features = np.array(data['features']).reshape(1, -1)

    # Make predictions
    prediction = model.predict(features)

    # Return the prediction
    return jsonify({'prediction': int(prediction[0])})

# Save the generator model in the SavedModel format
tf.saved_model.save(generator, 'path/to/saved_model_directory')